{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cc9b1242-4d80-4fdf-9fd3-92943534c51a",
      "metadata": {
        "id": "cc9b1242-4d80-4fdf-9fd3-92943534c51a"
      },
      "source": [
        "# MobileNetV2 Pretraining on UnityEyes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow==2.18.0\n",
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Glx2Vgflr72J",
        "outputId": "662fdf45-1f12-44eb-adae-ae3bdee5f3e8",
        "collapsed": true
      },
      "id": "Glx2Vgflr72J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.18.0\n",
            "Uninstalling tensorflow-2.18.0:\n",
            "  Successfully uninstalled tensorflow-2.18.0\n",
            "Collecting tensorflow==2.18.0\n",
            "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.18.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.18.0) (0.1.2)\n",
            "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow\n",
            "Successfully installed tensorflow-2.18.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              },
              "id": "c257360458654f669bf16914820f99d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-4.22.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: flax>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.10.6)\n",
            "Requirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (6.5.2)\n",
            "Requirement already satisfied: jax>=0.4.13 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.5.2)\n",
            "Requirement already satisfied: jaxlib>=0.4.13 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.5.1)\n",
            "Requirement already satisfied: tensorflow<3,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: tf-keras>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-decision-forests>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: six<2,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (1.17.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.16.1 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.16.1)\n",
            "Collecting packaging~=23.1 (from tensorflowjs)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (2.0.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.2.4)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.11.13)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.74)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (13.9.4)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (4.13.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (6.0.2)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.9)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (1.15.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (18.1.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (75.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.13.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.37.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.45.1)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (3.1.1)\n",
            "Requirement already satisfied: ydf in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.11.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (2.19.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.1.3)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.11/dist-packages (from optax->flax>=0.7.2->tensorflowjs) (0.1.89)\n",
            "Requirement already satisfied: etils[epy] in /usr/local/lib/python3.11/dist-packages (from optax->flax>=0.7.2->tensorflowjs) (1.12.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.6.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (4.12.3)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (3.20.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2025.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.87->optax->flax>=0.7.2->tensorflowjs) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.2->tensorflowjs) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (2025.3.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (3.21.0)\n",
            "Downloading tensorflowjs-4.22.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: packaging, tensorflowjs\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "google-cloud-bigquery 3.32.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed packaging-23.2 tensorflowjs-4.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "292565d7-cc2d-4467-bf21-6c0802bee8b1",
      "metadata": {
        "id": "292565d7-cc2d-4467-bf21-6c0802bee8b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "203c0e1c-b26c-41ab-9410-bb61a8621d6f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<p style=\"margin:0px;\">🌲 Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
              "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
              "        Decision Forests</a> using the same algorithms but with more features and faster\n",
              "    training!\n",
              "</p>\n",
              "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
              "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
              "        <p\n",
              "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
              "            Old code</p>\n",
              "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
              "import tensorflow_decision_forests as tfdf\n",
              "\n",
              "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
              "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
              "model.fit(tf_ds)\n",
              "</pre>\n",
              "    </div>\n",
              "    <div style=\"width: 5px;\"></div>\n",
              "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
              "        <p\n",
              "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
              "            New code</p>\n",
              "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
              "import ydf\n",
              "\n",
              "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
              "</pre>\n",
              "    </div>\n",
              "</div>\n",
              "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
              "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
              "        guide</a>)</p>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflowjs as tfjs\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os, shutil, random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "random.seed(42028)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i72glenvxTym",
        "outputId": "3f54f182-38d6-492c-f0e2-03f853e04bba"
      },
      "id": "i72glenvxTym",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May 25 09:55:01 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0             47W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TF Version:\", tf.__version__)\n",
        "print(\"GPU:\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liZoLrRpsAtK",
        "outputId": "6dc81bbe-ab78-4e89-f144-979eef66697e"
      },
      "id": "liZoLrRpsAtK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Version: 2.18.0\n",
            "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53oWzNbLOpLr",
        "outputId": "8a15f1dd-05b1-44f6-a861-2cdf3536d631"
      },
      "id": "53oWzNbLOpLr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_DIR = \"/content/drive/Shareddrives/OmniClick Team\"\n",
        "DATA_ROOT_DIR = os.path.join(PROJECT_DIR, \"datasets\")\n",
        "UNITY_DATA_DIR = os.path.join(DATA_ROOT_DIR, 'UnityEyes')\n",
        "UNITY_SUBSET_DIR = os.path.join(DATA_ROOT_DIR, 'UnityEyesSubset')\n",
        "\n",
        "BEST_MODEL_PATH = os.path.join(PROJECT_DIR, \"notebooks/weights/mobilenetv2_unity_best.keras\")\n",
        "LAST_MODEL_PATH = os.path.join(PROJECT_DIR, \"notebooks/weights/mobilenetv2_unity_last.keras\")\n",
        "TFJS_MODEL_DIR = os.path.join(PROJECT_DIR, \"notebooks/weights/mobilenetv2_unity_tfjs\")\n",
        "TF_SAVE_MODEL_DIR = os.path.join(PROJECT_DIR, \"notebooks/weights/mobilenetv2_unity_tf\")"
      ],
      "metadata": {
        "id": "hSyUHVSnOmTS"
      },
      "id": "hSyUHVSnOmTS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls \"$DATA_ROOT_DIR\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn1w7wJxU5Zt",
        "outputId": "e1dd80b3-0e9f-492c-830b-3af7be9454ad"
      },
      "id": "cn1w7wJxU5Zt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "columbia_gaze_data_set.zip  \u001b[0m\u001b[01;34mOurWebcamDataset\u001b[0m/  \u001b[01;34mUnityEyesSubset\u001b[0m/  u_train.zip\n",
            "\u001b[01;34mColumbiaGazeProcessed\u001b[0m/      \u001b[01;34mUnityEyes\u001b[0m/         u_test.zip        u_val.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def subsample_directory(src_dir, dst_dir, sample_fraction=0.2):\n",
        "    os.makedirs(dst_dir, exist_ok=True)\n",
        "\n",
        "    for class_name in sorted(os.listdir(src_dir)):\n",
        "        src_class = os.path.join(src_dir, class_name)\n",
        "        dst_class = os.path.join(dst_dir, class_name)\n",
        "        os.makedirs(dst_class, exist_ok=True)\n",
        "\n",
        "        all_images = os.listdir(src_class)\n",
        "        sampled_images = random.sample(all_images, int(len(all_images) * sample_fraction))\n",
        "\n",
        "        for img in sampled_images:\n",
        "            shutil.copy(os.path.join(src_class, img), os.path.join(dst_class, img))\n",
        "\n",
        "# for split in ['train', 'val', 'test']:\n",
        "for split in ['test']:\n",
        "    subsample_directory(\n",
        "        src_dir=os.path.join(UNITY_DATA_DIR, split),\n",
        "        dst_dir=os.path.join(UNITY_SUBSET_DIR, split),\n",
        "        sample_fraction=0.1  # 10% subset\n",
        "    )"
      ],
      "metadata": {
        "id": "TiXCna6gT_uk"
      },
      "id": "TiXCna6gT_uk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8e8de48-3162-4b33-9e23-72517b4adc42",
      "metadata": {
        "id": "e8e8de48-3162-4b33-9e23-72517b4adc42",
        "outputId": "34b907c0-4777-4cd6-b0d6-6a4f12355923",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6103 images belonging to 8 classes.\n",
            "Found 7247 images belonging to 8 classes.\n",
            "Found 8232 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "IMG_SIZE = (96, 96)\n",
        "BATCH_SIZE = 768\n",
        "\n",
        "unity_train_dir = os.path.join(UNITY_SUBSET_DIR, 'train')\n",
        "unity_val_dir = os.path.join(UNITY_SUBSET_DIR, 'val')\n",
        "unity_test_dir = os.path.join(UNITY_SUBSET_DIR, 'test')\n",
        "unity_class_names = sorted(os.listdir(unity_train_dir))\n",
        "unity_class_indices = {name: idx for idx, name in enumerate(unity_class_names)}\n",
        "NUM_CLASSES_UNITY = len(unity_class_names)\n",
        "\n",
        "# Data Aug for Unity set\n",
        "unity_train_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    brightness_range=[0.7, 1.3],\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ").flow_from_directory(\n",
        "    unity_train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "unity_val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    unity_val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "unity_test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    unity_test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Checkpoints\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        BEST_MODEL_PATH,\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        LAST_MODEL_PATH,\n",
        "        save_best_only=False,\n",
        "        save_weights_only=False,\n",
        "        verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=20,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4ec0feb-3e2c-487e-ae32-8e6096b33085",
      "metadata": {
        "id": "c4ec0feb-3e2c-487e-ae32-8e6096b33085",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07be0f6e-af79-4363-9ffa-734d5d4815e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = MobileNetV2(input_shape=IMG_SIZE + (3,), include_top=False, weights='imagenet')\n",
        "base_model.trainable = True\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(NUM_CLASSES_UNITY, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abeb3d4e-93b8-4787-a7af-06d83c4353ed",
      "metadata": {
        "id": "abeb3d4e-93b8-4787-a7af-06d83c4353ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b0a5ba-15b9-48c1-ba2e-5d8980276726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432s/step - accuracy: 0.1581 - loss: 2.4527  \n",
            "Epoch 1: val_loss improved from inf to 2.40718, saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_best.keras\n",
            "\n",
            "Epoch 1: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9015s\u001b[0m 1215s/step - accuracy: 0.1619 - loss: 2.4302 - val_accuracy: 0.2190 - val_loss: 2.4072\n",
            "Epoch 2/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3042 - loss: 1.8370\n",
            "Epoch 2: val_loss improved from 2.40718 to 2.08601, saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_best.keras\n",
            "\n",
            "Epoch 2: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 8s/step - accuracy: 0.3055 - loss: 1.8337 - val_accuracy: 0.2691 - val_loss: 2.0860\n",
            "Epoch 3/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3687 - loss: 1.6206\n",
            "Epoch 3: val_loss improved from 2.08601 to 1.93012, saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_best.keras\n",
            "\n",
            "Epoch 3: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 8s/step - accuracy: 0.3710 - loss: 1.6156 - val_accuracy: 0.3223 - val_loss: 1.9301\n",
            "Epoch 4/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4449 - loss: 1.4405\n",
            "Epoch 4: val_loss improved from 1.93012 to 1.80527, saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_best.keras\n",
            "\n",
            "Epoch 4: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 8s/step - accuracy: 0.4445 - loss: 1.4386 - val_accuracy: 0.3393 - val_loss: 1.8053\n",
            "Epoch 5/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4791 - loss: 1.3300\n",
            "Epoch 5: val_loss improved from 1.80527 to 1.72393, saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_best.keras\n",
            "\n",
            "Epoch 5: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 8s/step - accuracy: 0.4790 - loss: 1.3299 - val_accuracy: 0.3356 - val_loss: 1.7239\n",
            "Epoch 6/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4949 - loss: 1.2643\n",
            "Epoch 6: val_loss improved from 1.72393 to 1.66665, saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_best.keras\n",
            "\n",
            "Epoch 6: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 8s/step - accuracy: 0.4958 - loss: 1.2631 - val_accuracy: 0.3462 - val_loss: 1.6666\n",
            "Epoch 7/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5265 - loss: 1.2099\n",
            "Epoch 7: val_loss improved from 1.66665 to 1.64184, saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_best.keras\n",
            "\n",
            "Epoch 7: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.5271 - loss: 1.2072 - val_accuracy: 0.3515 - val_loss: 1.6418\n",
            "Epoch 8/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5515 - loss: 1.1278\n",
            "Epoch 8: val_loss improved from 1.64184 to 1.62686, saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_best.keras\n",
            "\n",
            "Epoch 8: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 8s/step - accuracy: 0.5516 - loss: 1.1274 - val_accuracy: 0.3568 - val_loss: 1.6269\n",
            "Epoch 9/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5783 - loss: 1.0777\n",
            "Epoch 9: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 9: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 8s/step - accuracy: 0.5780 - loss: 1.0771 - val_accuracy: 0.3567 - val_loss: 1.6296\n",
            "Epoch 10/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5869 - loss: 1.0360\n",
            "Epoch 10: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 10: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 8s/step - accuracy: 0.5875 - loss: 1.0345 - val_accuracy: 0.3545 - val_loss: 1.6381\n",
            "Epoch 11/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6094 - loss: 0.9914\n",
            "Epoch 11: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 11: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 8s/step - accuracy: 0.6101 - loss: 0.9884 - val_accuracy: 0.3519 - val_loss: 1.6442\n",
            "Epoch 12/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6265 - loss: 0.9393\n",
            "Epoch 12: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 12: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 7s/step - accuracy: 0.6268 - loss: 0.9381 - val_accuracy: 0.3488 - val_loss: 1.6652\n",
            "Epoch 13/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6461 - loss: 0.8871\n",
            "Epoch 13: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 13: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 8s/step - accuracy: 0.6455 - loss: 0.8881 - val_accuracy: 0.3563 - val_loss: 1.6589\n",
            "Epoch 14/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6652 - loss: 0.8413\n",
            "Epoch 14: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 14: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 7s/step - accuracy: 0.6657 - loss: 0.8405 - val_accuracy: 0.3548 - val_loss: 1.6613\n",
            "Epoch 15/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6881 - loss: 0.7939\n",
            "Epoch 15: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 15: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 7s/step - accuracy: 0.6879 - loss: 0.7946 - val_accuracy: 0.3556 - val_loss: 1.6801\n",
            "Epoch 16/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6920 - loss: 0.7695\n",
            "Epoch 16: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 16: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 7s/step - accuracy: 0.6925 - loss: 0.7680 - val_accuracy: 0.3575 - val_loss: 1.6759\n",
            "Epoch 17/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7169 - loss: 0.7252\n",
            "Epoch 17: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 17: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.7166 - loss: 0.7250 - val_accuracy: 0.3606 - val_loss: 1.6998\n",
            "Epoch 18/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7284 - loss: 0.6911\n",
            "Epoch 18: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 18: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 7s/step - accuracy: 0.7289 - loss: 0.6897 - val_accuracy: 0.3662 - val_loss: 1.6874\n",
            "Epoch 19/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7464 - loss: 0.6424\n",
            "Epoch 19: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 19: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 8s/step - accuracy: 0.7466 - loss: 0.6423 - val_accuracy: 0.3606 - val_loss: 1.7490\n",
            "Epoch 20/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7781 - loss: 0.5777\n",
            "Epoch 20: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 20: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 8s/step - accuracy: 0.7775 - loss: 0.5789 - val_accuracy: 0.3603 - val_loss: 1.7772\n",
            "Epoch 21/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7755 - loss: 0.5551\n",
            "Epoch 21: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 21: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 8s/step - accuracy: 0.7760 - loss: 0.5543 - val_accuracy: 0.3575 - val_loss: 1.8439\n",
            "Epoch 22/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7949 - loss: 0.5318\n",
            "Epoch 22: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 22: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 7s/step - accuracy: 0.7952 - loss: 0.5309 - val_accuracy: 0.3607 - val_loss: 1.8848\n",
            "Epoch 23/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8039 - loss: 0.4962\n",
            "Epoch 23: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 23: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 7s/step - accuracy: 0.8050 - loss: 0.4941 - val_accuracy: 0.3599 - val_loss: 1.9218\n",
            "Epoch 24/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8222 - loss: 0.4503\n",
            "Epoch 24: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 24: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 8s/step - accuracy: 0.8221 - loss: 0.4507 - val_accuracy: 0.3662 - val_loss: 1.9399\n",
            "Epoch 25/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8306 - loss: 0.4347\n",
            "Epoch 25: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 25: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.8310 - loss: 0.4341 - val_accuracy: 0.3676 - val_loss: 1.9472\n",
            "Epoch 26/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8386 - loss: 0.4189\n",
            "Epoch 26: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 26: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.8391 - loss: 0.4170 - val_accuracy: 0.3662 - val_loss: 2.0192\n",
            "Epoch 27/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8544 - loss: 0.3704\n",
            "Epoch 27: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 27: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 7s/step - accuracy: 0.8549 - loss: 0.3699 - val_accuracy: 0.3619 - val_loss: 2.0765\n",
            "Epoch 28/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8662 - loss: 0.3495\n",
            "Epoch 28: val_loss did not improve from 1.62686\n",
            "\n",
            "Epoch 28: saving model to /content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_last.keras\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.8664 - loss: 0.3493 - val_accuracy: 0.3694 - val_loss: 1.9945\n",
            "Saved artifact at '/content/drive/Shareddrives/OmniClick Team/notebooks/weights/mobilenetv2_unity_tf'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 8), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132831344256080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801219408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801219984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830807865488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830807865296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830807865104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801219216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801218640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801220368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801220176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801220752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801222288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801218832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801219024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801221328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801224208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801226128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801224784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801225168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801224016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801227664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801227280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801226896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801227856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801226512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801229968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801230352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801230736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801230544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801225360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801228816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184227280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184227856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801229584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830801229200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184228816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184229200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184229584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184229392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184228048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184227088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184231312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184231696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184231504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184227664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184230352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184233424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184233808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184233616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184230736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184234960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184235344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184235728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184235536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184232464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184236880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184237264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184237648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184237456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184233040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184238800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184239184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184239568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184239376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184234576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184240720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184241104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184241488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184241296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184236496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184242640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184589648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184238416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184242832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184588112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184243024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184590224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184588880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184240336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184588496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184590608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184590992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184591376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184591184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184589072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184592528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184592912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184593296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184593104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184589264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184594448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184594832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184595216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184595024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184587920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184596368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184596752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184597136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184596944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184592144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184598288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184598864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184594064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830807858000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830807857808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184595984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184600208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184600592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184600400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184597520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184601744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184602128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184602512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184602320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184599248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184599824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184948176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184948752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184601360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184600976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184949712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184950096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184950480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184950288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184948944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184951632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184952016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184952400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184952208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184947984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184953552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184953936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184954320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184954128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184949328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184955472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184955856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184956240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184956048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184951248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184957392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184957776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184958160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184957968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184953168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184959312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184959696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184960080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184959888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184955088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184961232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184961616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184962000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184961808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184957008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184963152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184962768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184962384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184963728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184958928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132830184960848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674620304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674620688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674620496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674618960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674621840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674622224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674622608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674622416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674619728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674623760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674624144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674624528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674624336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674619344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674625680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674626064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674626448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674626256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674621456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674627600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674627984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674628368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674628176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674623376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674629520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674629904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674630288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674630096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674625296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674631440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674631824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674632208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674632016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674627216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674633360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674633744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674634128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674633936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674629136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674631056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674979600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674980368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674632976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674632592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674981328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674981712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674982096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674981904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674980560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674983248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674983632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674984016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674983824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674979408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674985168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674985552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674985936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674985744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674980944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674987088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674987472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674987856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674987664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674982864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674989008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674989392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674989776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674989584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674984784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674990928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674991312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674991696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674991504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674986704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674992848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674990544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674994192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674992464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674988624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674994768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674994384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674993232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674995344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674993040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829674993616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675423120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675422160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675422928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675421968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675424656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675425040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675425424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675425232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675422352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675426576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675426960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675427344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675427152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675423504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675426192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675430032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675429264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132829675431184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "history = model.fit(\n",
        "    unity_train_gen,\n",
        "    validation_data=unity_val_gen,\n",
        "    epochs=100,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "model.export(TF_SAVE_MODEL_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorflowjs_converter --input_format=tf_saved_model TF_SAVE_MODEL_DIR TFJS_MODEL_DIR"
      ],
      "metadata": {
        "id": "c1-j7ZnXSsfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354c1a20-f3c2-44f7-dc49-124f004f6639"
      },
      "id": "c1-j7ZnXSsfw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-25 13:11:47.426210: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748178707.447858   54494 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748178707.454436   54494 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[32m🌲 Try \u001b[0m\u001b[34mhttps://ydf.readthedocs.io\u001b[0m\u001b[32m, the successor of TensorFlow Decision Forests with more features and faster training!\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tensorflowjs_converter\", line 8, in <module>\n",
            "    sys.exit(pip_main())\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflowjs/converters/converter.py\", line 959, in pip_main\n",
            "    main([' '.join(sys.argv[1:])])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflowjs/converters/converter.py\", line 963, in main\n",
            "    convert(argv[0].split(' '))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflowjs/converters/converter.py\", line 949, in convert\n",
            "    _dispatch_converter(input_format, output_format, args, quantization_dtype_map,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflowjs/converters/converter.py\", line 655, in _dispatch_converter\n",
            "    tf_saved_model_conversion_v2.convert_tf_saved_model(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py\", line 982, in convert_tf_saved_model\n",
            "    _convert_tf_saved_model(output_dir, saved_model_dir=saved_model_dir,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py\", line 757, in _convert_tf_saved_model\n",
            "    saved_model_sigature = _find_signature(saved_model_dir, saved_model_tags,\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py\", line 589, in _find_signature\n",
            "    meta_graph = get_meta_graph_def(saved_model_dir, saved_model_tags)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/tools/saved_model_utils.py\", line 113, in get_meta_graph_def\n",
            "    saved_model = read_saved_model(saved_model_dir)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/tools/saved_model_utils.py\", line 51, in read_saved_model\n",
            "    raise IOError(\"SavedModel file does not exist at: %s\" % saved_model_dir)\n",
            "OSError: SavedModel file does not exist at: TF_SAVE_MODEL_DIR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d752adc-4387-4828-b38d-b565941192e4",
      "metadata": {
        "id": "2d752adc-4387-4828-b38d-b565941192e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "03e05b2f-2e27-469c-8ed0-f5f40836667a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c6b44f42faf5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munity_test_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Accuracy: {test_acc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# Create an iterator that yields batches of input/target data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             epoch_iterator = TFEpochIterator(\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribute_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             dataset = self._distribute_strategy.experimental_distribute_dataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             batches = [\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             batches = [\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         ]\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mfilepaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             img = image_utils.load_img(\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         raise TypeError(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(unity_test_gen)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "827ba48f-713c-4b59-a1e7-e598996b3804",
      "metadata": {
        "id": "827ba48f-713c-4b59-a1e7-e598996b3804"
      },
      "outputs": [],
      "source": [
        "best_model = tf.keras.models.load_model(BEST_MODEL_PATH)\n",
        "last_model = tf.keras.models.load_model(LAST_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69dd425c-6935-4ea7-bcd8-8b39741a0a04",
      "metadata": {
        "id": "69dd425c-6935-4ea7-bcd8-8b39741a0a04"
      },
      "outputs": [],
      "source": [
        "model = best_model\n",
        "\n",
        "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    os.path.join(UNITY_SUBSET_DIR, 'test'),\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Predict\n",
        "y_pred_probs = model.predict(unity_test_gen)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = unity_test_gen.classes\n",
        "class_names = list(unity_test_gen.class_indices.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8492f9bd-2151-4bca-b14d-98bd0ebd8f7e",
      "metadata": {
        "id": "8492f9bd-2151-4bca-b14d-98bd0ebd8f7e"
      },
      "outputs": [],
      "source": [
        "# 1. Plot training curves\n",
        "def plot_training_curves(history):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_training_curves(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a69f5277-c917-4ac2-af52-69ad299523ae",
      "metadata": {
        "id": "a69f5277-c917-4ac2-af52-69ad299523ae"
      },
      "outputs": [],
      "source": [
        "# 2. Classification report\n",
        "report = classification_report(y_true, y_pred, target_names=unity_class_names, output_dict=True)\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "report_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3c1e50-2c78-485c-9bed-a2bc41898d8c",
      "metadata": {
        "id": "dd3c1e50-2c78-485c-9bed-a2bc41898d8c"
      },
      "outputs": [],
      "source": [
        "# 3. Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6e294f5-dd85-4c47-ab20-1f95fa083774",
      "metadata": {
        "id": "f6e294f5-dd85-4c47-ab20-1f95fa083774"
      },
      "outputs": [],
      "source": [
        "# 4. Inference examples\n",
        "def plot_inference_examples(generator, y_pred, class_names, num_examples=8):\n",
        "    fig, axes = plt.subplots(2, num_examples // 2, figsize=(16, 5))\n",
        "    axes = axes.flatten()\n",
        "    for i in range(num_examples):\n",
        "        img, label = generator[i]\n",
        "        pred_label = class_names[np.argmax(model.predict(np.expand_dims(img[0], axis=0)))]\n",
        "        true_label = class_names[np.argmax(label[0])]\n",
        "        axes[i].imshow(img[0])\n",
        "        axes[i].set_title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
        "        axes[i].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display\n",
        "plot_inference_examples(unity_test_gen, y_pred, class_names)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}