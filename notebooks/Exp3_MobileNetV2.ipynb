{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc9b1242-4d80-4fdf-9fd3-92943534c51a",
   "metadata": {},
   "source": [
    "# Experiment 3 MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "292565d7-cc2d-4467-bf21-6c0802bee8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 04:40:31.148240: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-23 04:40:31.165305: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747975231.184556   20448 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747975231.190493   20448 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-23 04:40:31.210345: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e8de48-3162-4b33-9e23-72517b4adc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4125 images belonging to 9 classes.\n",
      "Found 912 images belonging to 9 classes.\n",
      "Found 886 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/home/sagemaker-user/gesture-gaze-extension/datasets/ColumbiaGazeProcessed\"\n",
    "IMG_SIZE = (96, 96)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = len(os.listdir(os.path.join(DATA_DIR, 'train')))\n",
    "\n",
    "# Data Aug\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ").flow_from_directory(\n",
    "    os.path.join(DATA_DIR, 'train'),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    os.path.join(DATA_DIR, 'val'),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    os.path.join(DATA_DIR, 'test'),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85dfb802-ca56-482c-8083-ae5b3cc8db96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1747975270.399661   20448 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 207ms/step - accuracy: 0.1599 - loss: 2.2877 - val_accuracy: 0.2467 - val_loss: 1.9344\n",
      "Epoch 2/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 197ms/step - accuracy: 0.2477 - loss: 1.9139 - val_accuracy: 0.2588 - val_loss: 1.8144\n",
      "Epoch 3/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 202ms/step - accuracy: 0.2742 - loss: 1.8228 - val_accuracy: 0.2961 - val_loss: 1.7285\n",
      "Epoch 4/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 207ms/step - accuracy: 0.2835 - loss: 1.7677 - val_accuracy: 0.2829 - val_loss: 1.7023\n",
      "Epoch 5/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 205ms/step - accuracy: 0.3150 - loss: 1.7056 - val_accuracy: 0.3059 - val_loss: 1.6716\n",
      "Epoch 6/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 202ms/step - accuracy: 0.2931 - loss: 1.6920 - val_accuracy: 0.3059 - val_loss: 1.6267\n",
      "Epoch 7/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 203ms/step - accuracy: 0.3163 - loss: 1.6807 - val_accuracy: 0.3268 - val_loss: 1.6275\n",
      "Epoch 8/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 203ms/step - accuracy: 0.3355 - loss: 1.6169 - val_accuracy: 0.3169 - val_loss: 1.6380\n",
      "Epoch 9/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 202ms/step - accuracy: 0.3329 - loss: 1.6329 - val_accuracy: 0.3531 - val_loss: 1.6010\n",
      "Epoch 10/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 199ms/step - accuracy: 0.3499 - loss: 1.5834 - val_accuracy: 0.3377 - val_loss: 1.5968\n",
      "Epoch 11/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 200ms/step - accuracy: 0.3561 - loss: 1.5540 - val_accuracy: 0.3695 - val_loss: 1.5507\n",
      "Epoch 12/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 199ms/step - accuracy: 0.3648 - loss: 1.5546 - val_accuracy: 0.3607 - val_loss: 1.5648\n",
      "Epoch 13/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 201ms/step - accuracy: 0.3565 - loss: 1.5451 - val_accuracy: 0.3410 - val_loss: 1.5823\n",
      "Epoch 14/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 205ms/step - accuracy: 0.3652 - loss: 1.5401 - val_accuracy: 0.3607 - val_loss: 1.6032\n",
      "Epoch 15/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 207ms/step - accuracy: 0.3728 - loss: 1.5232 - val_accuracy: 0.3553 - val_loss: 1.5905\n",
      "Epoch 16/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 205ms/step - accuracy: 0.3599 - loss: 1.5334 - val_accuracy: 0.3816 - val_loss: 1.5431\n",
      "Epoch 17/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 202ms/step - accuracy: 0.3686 - loss: 1.5334 - val_accuracy: 0.3575 - val_loss: 1.5851\n",
      "Epoch 18/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 203ms/step - accuracy: 0.3838 - loss: 1.4826 - val_accuracy: 0.3882 - val_loss: 1.5636\n",
      "Epoch 19/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 202ms/step - accuracy: 0.3741 - loss: 1.5260 - val_accuracy: 0.3871 - val_loss: 1.5921\n",
      "Epoch 20/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 198ms/step - accuracy: 0.3992 - loss: 1.4842 - val_accuracy: 0.3717 - val_loss: 1.6039\n",
      "Epoch 21/30\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 198ms/step - accuracy: 0.3979 - loss: 1.4590 - val_accuracy: 0.3432 - val_loss: 1.6325\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.3433 - loss: 1.6537\n",
      "Test Accuracy: 0.3871\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(input_shape=IMG_SIZE + (3,), include_top=False, weights='imagenet')\n",
    "base_model.trainable = True\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(test_gen)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
