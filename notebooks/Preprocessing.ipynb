{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c3bb35-ac93-43e6-b59b-c754d69d1138",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a432f7-ad2a-46a0-a4cf-4d18434709bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.18.1 in /opt/conda/lib/python3.12/site-packages (2.18.1)\n",
      "Requirement already satisfied: protobuf==4.25.3 in /opt/conda/lib/python3.12/site-packages (4.25.3)\n",
      "Requirement already satisfied: mediapipe==0.10.21 in /opt/conda/lib/python3.12/site-packages (0.10.21)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (24.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (80.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.1) (0.5.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.12/site-packages (from mediapipe==0.10.21) (23.2.0)\n",
      "Requirement already satisfied: jax in /opt/conda/lib/python3.12/site-packages (from mediapipe==0.10.21) (0.6.1)\n",
      "Requirement already satisfied: jaxlib in /opt/conda/lib/python3.12/site-packages (from mediapipe==0.10.21) (0.6.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (from mediapipe==0.10.21) (3.10.1)\n",
      "Requirement already satisfied: opencv-contrib-python in /opt/conda/lib/python3.12/site-packages (from mediapipe==0.10.21) (4.11.0.86)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /opt/conda/lib/python3.12/site-packages (from mediapipe==0.10.21) (0.5.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.12/site-packages (from mediapipe==0.10.21) (0.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.18.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.18.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.18.1) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.18.1) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.1) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.1) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.1) (3.1.3)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow==2.18.1) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow==2.18.1) (0.0.9)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow==2.18.1) (0.15.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/conda/lib/python3.12/site-packages (from sounddevice>=0.4.4->mediapipe==0.10.21) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.12/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.21) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow==2.18.1) (3.0.2)\n",
      "Requirement already satisfied: scipy>=1.11.1 in /opt/conda/lib/python3.12/site-packages (from jax->mediapipe==0.10.21) (1.15.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe==0.10.21) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe==0.10.21) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe==0.10.21) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe==0.10.21) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe==0.10.21) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe==0.10.21) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe==0.10.21) (2.9.0.post0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow==2.18.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow==2.18.1) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.18.1) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.18.1 protobuf==4.25.3 mediapipe==0.10.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4e75975-4459-40c0-95cc-c06f25e37969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1747973161.455395   24894 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747973161.473140   24893 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import mediapipe as mp\n",
    "\n",
    "random.seed(42028)\n",
    "\n",
    "RAW_DATA_DIR = \"/home/sagemaker-user/gesture-gaze-extension/datasets/Columbia Gaze Data Set\"\n",
    "OUTPUT_DIR = \"/home/sagemaker-user/gesture-gaze-extension/datasets/ColumbiaGazeProcessed\"\n",
    "SPLITS = ['train', 'val', 'test']\n",
    "SPLIT_RATIOS = {'train': 0.7, 'val': 0.15, 'test': 0.15}\n",
    "\n",
    "# MediaPipe setup\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True, max_num_faces=1)\n",
    "\n",
    "def extract_gaze_from_filename(filename):\n",
    "    match = re.search(r'(-?\\d+)P_(-?\\d+)V_(-?\\d+)H', filename)\n",
    "    if match:\n",
    "        _, v, h = int(match.group(1)), int(match.group(2)), int(match.group(3))\n",
    "        return v, h\n",
    "    return None, None\n",
    "\n",
    "def classify_gaze(v, h):\n",
    "    if v == 0 and h == 0:\n",
    "        return 'center'\n",
    "    elif v == 0 and h < 0:\n",
    "        return 'left'\n",
    "    elif v == 0 and h > 0:\n",
    "        return 'right'\n",
    "    elif v > 0 and h == 0:\n",
    "        return 'up'\n",
    "    elif v < 0 and h == 0:\n",
    "        return 'down'\n",
    "    elif v > 0 and h < 0:\n",
    "        return 'up_left'\n",
    "    elif v > 0 and h > 0:\n",
    "        return 'up_right'\n",
    "    elif v < 0 and h < 0:\n",
    "        return 'down_left'\n",
    "    elif v < 0 and h > 0:\n",
    "        return 'down_right'\n",
    "    return None\n",
    "\n",
    "def crop_eye_region(image, landmarks):\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    LEFT_EYE_LANDMARKS = [33, 133, 160, 159, 158, 157, 173, 246]\n",
    "    RIGHT_EYE_LANDMARKS = [362, 263, 387, 386, 385, 384, 398, 466]\n",
    "\n",
    "    # Extract (x, y) pixel coordinates\n",
    "    left_eye = np.array([[int(landmarks[idx].x * w), int(landmarks[idx].y * h)] for idx in LEFT_EYE_LANDMARKS])\n",
    "    right_eye = np.array([[int(landmarks[idx].x * w), int(landmarks[idx].y * h)] for idx in RIGHT_EYE_LANDMARKS])\n",
    "    eyes = np.vstack((left_eye, right_eye))\n",
    "\n",
    "    x, y, eye_w, eye_h = cv2.boundingRect(eyes)\n",
    "    margin = 100\n",
    "    x = max(0, x - margin)\n",
    "    y = max(0, y - margin)\n",
    "    x2 = min(w, x + eye_w + 2 * margin)\n",
    "    y2 = min(h, y + eye_h + 2 * margin)\n",
    "\n",
    "    return image[y:y2, x:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0fc41-1aa6-4bd8-95e9-316372e54fc9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train/down_left:  36%|███▌      | 211/588 [00:32<00:57,  6.59it/s]"
     ]
    }
   ],
   "source": [
    "image_paths = glob(os.path.join(RAW_DATA_DIR, \"*/*.jpg\"))\n",
    "labeled_data = defaultdict(list)\n",
    "\n",
    "for path in image_paths:\n",
    "    filename = os.path.basename(path)\n",
    "    v, h = extract_gaze_from_filename(filename)\n",
    "    label = classify_gaze(v, h)\n",
    "    if label:\n",
    "        labeled_data[label].append(path)\n",
    "\n",
    "for label, paths in labeled_data.items():\n",
    "    random.shuffle(paths)\n",
    "    n = len(paths)\n",
    "    train_end = int(n * SPLIT_RATIOS['train'])\n",
    "    val_end = train_end + int(n * SPLIT_RATIOS['val'])\n",
    "    split_dict = {\n",
    "        'train': paths[:train_end],\n",
    "        'val': paths[train_end:val_end],\n",
    "        'test': paths[val_end:]\n",
    "    }\n",
    "\n",
    "    for split, split_paths in split_dict.items():\n",
    "        out_dir = os.path.join(OUTPUT_DIR, split, label)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        for img_path in tqdm(split_paths, desc=f\"{split}/{label}\"):\n",
    "            img = cv2.imread(img_path)\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            results = face_mesh.process(img_rgb)\n",
    "            if results.multi_face_landmarks:\n",
    "                cropped = crop_eye_region(img, results.multi_face_landmarks[0].landmark)\n",
    "                out_path = os.path.join(out_dir, os.path.basename(img_path))\n",
    "                cv2.imwrite(out_path, cropped)\n",
    "\n",
    "face_mesh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f280dfa-c3c1-4cd6-bd09-9fd7a82189a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Labels</th>\n",
       "      <th># of Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>down_left</th>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>down</th>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>down_right</th>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>center</th>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up_left</th>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up</th>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up_right</th>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Labels      # of Images\n",
       "down_left           840\n",
       "down                280\n",
       "down_right          840\n",
       "left                840\n",
       "center              280\n",
       "right               840\n",
       "up_left             840\n",
       "up                  280\n",
       "up_right            840"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "df = pd.DataFrame({k: [len(v)] for k, v in labeled_data.items()}, index=[\"# of Images\"]).T\n",
    "df.columns.name = \"Labels\"\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a358ed0-1dca-4533-952b-dec03014f096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sagemaker-user/gesture-gaze-extension/notebooks/ColumbiaGazeProcessed.zip'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.make_archive(\"ColumbiaGazeProcessed\",\"zip\",OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
